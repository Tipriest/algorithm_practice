{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt update > /dev/null; apt install aria2 git-lfs axel -y > /dev/null\n",
    "# !pip install ltralytics==8.2.0 numpy pandas opencv-python Pillow matplotlib > /dev/null\n",
    "# !axel -n 12 -a http://mirror.coggle.club/seg_risky_testing_data.zip; unzip -q seg_risky_testing_data.zip\n",
    "# !axel -n 12 -a  http://mirror.coggle.club/seg_risky_training_data_00.zip; unzip -q seg_risky_training_data_00.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics==8.2.0 numpy pandas opencv-python Pillow matplotlib > /dev/null\n",
    "# !axel -n 12 -a http://mirror.coggle.club/seg_risky_testing_data.zip -o ~/data/seg_risky/seg_risky_testing_data.zip\n",
    "# !unzip -q /home/tipriest/data/seg_risky/seg_risky_testing_data.zip -d /home/tipriest/data/seg_risky/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !axel -n 12 -a  http://mirror.coggle.club/seg_risky_training_data_00.zip -o ~/data/seg_risky/seg_risky_training_data_00.zip\n",
    "# !unzip -q /home/tipriest/data/seg_risky/seg_risky_training_data_00.zip -d /home/tipriest/data/seg_risky/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/tipriest/data/seg_risky\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# FIXME: ËøôÈáå‰ΩøÁî®ÁöÑÊï∞ÊçÆÊòØ100‰∏áÊï∞ÊçÆ‰∏≠ÁöÑ6‰∏áÂº†\n",
    "training_anno = pd.read_csv('http://mirror.coggle.club/seg_risky_training_anno.csv')\n",
    "\n",
    "train_jpgs = [x.replace('/home/tipriest/data/seg_risky/', '') for x in glob.glob(os.path.join(data_path, '0/*.jpg'))]\n",
    "training_anno = training_anno[training_anno['Path'].isin(train_jpgs)]\n",
    "training_anno['Polygons'] = training_anno['Polygons'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainging_anno.shape =  (63785, 2)\n",
      "[[[393 398]\n",
      "  [442 398]\n",
      "  [442 420]\n",
      "  [393 420]]\n",
      "\n",
      " [[393 334]\n",
      "  [467 334]\n",
      "  [467 356]\n",
      "  [393 356]]\n",
      "\n",
      " [[  4 291]\n",
      "  [100 291]\n",
      "  [100 312]\n",
      "  [  4 312]]]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 63785 entries, 13 to 1020545\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Path      63785 non-null  object\n",
      " 1   Polygons  63785 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Polygons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0/0a3907dbf1ce7cd699020e0df8492920.jpg</td>\n",
       "      <td>[[[240, 403], [153, 397], [154, 346], [241, 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0/0d3898109a2f973bd18f9976a8669d77.jpg</td>\n",
       "      <td>[[[166, 69], [322, 62], [323, 72], [485, 62], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0/0dab23eb6a6359765bdf8a7570e7e83b.jpg</td>\n",
       "      <td>[[[174, 321], [174, 212], [331, 212], [331, 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0/02e87d696c089ef3bb98e6927f346d30.jpg</td>\n",
       "      <td>[[[126, 325], [126, 304], [156, 304], [156, 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0/0006b88e2b714a9d38c022e49cec28e4.jpg</td>\n",
       "      <td>[[[393.0, 398.0], [442.0, 398.0], [442.0, 420....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Path  \\\n",
       "13  0/0a3907dbf1ce7cd699020e0df8492920.jpg   \n",
       "17  0/0d3898109a2f973bd18f9976a8669d77.jpg   \n",
       "21  0/0dab23eb6a6359765bdf8a7570e7e83b.jpg   \n",
       "42  0/02e87d696c089ef3bb98e6927f346d30.jpg   \n",
       "51  0/0006b88e2b714a9d38c022e49cec28e4.jpg   \n",
       "\n",
       "                                             Polygons  \n",
       "13  [[[240, 403], [153, 397], [154, 346], [241, 35...  \n",
       "17  [[[166, 69], [322, 62], [323, 72], [485, 62], ...  \n",
       "21  [[[174, 321], [174, 212], [331, 212], [331, 32...  \n",
       "42  [[[126, 325], [126, 304], [156, 304], [156, 32...  \n",
       "51  [[[393.0, 398.0], [442.0, 398.0], [442.0, 420....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"trainging_anno.shape = \", training_anno.shape)\n",
    "print(np.array(training_anno['Polygons'].iloc[4], dtype=np.int32))\n",
    "print(training_anno.info())\n",
    "training_anno.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_seg_dataset_path = os.path.join(data_path, \"dataset\")\n",
    "yolo_seg_dataset_train_path = os.path.join(yolo_seg_dataset_path, \"train/\")\n",
    "yolo_seg_dataset_valid_path = os.path.join(yolo_seg_dataset_path, \"valid/\")\n",
    "\n",
    "if os.path.exists(yolo_seg_dataset_path):\n",
    "    shutil.rmtree(yolo_seg_dataset_path)\n",
    "os.makedirs(yolo_seg_dataset_train_path)\n",
    "os.makedirs(yolo_seg_dataset_valid_path)\n",
    "\n",
    "def normalize_polygon(polygon, img_width, img_height):\n",
    "    return [(x / img_width, y / img_height) for x, y in polygon]\n",
    "\n",
    "for row in training_anno.iloc[10000:].iterrows():\n",
    "    shutil.copy(os.path.join(data_path, row[1].Path), yolo_seg_dataset_train_path)\n",
    "    img = cv2.imread(os.path.join(data_path, row[1].Path))\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    txt_filename = os.path.join(yolo_seg_dataset_train_path + row[1].Path.split('/')[-1][:-4] + '.txt')\n",
    "    with open(txt_filename, 'w') as up:\n",
    "        for polygon in row[1].Polygons:\n",
    "            normalized_polygon = normalize_polygon(polygon, img_width, img_height)\n",
    "            normalized_coords = ' '.join([f'{coord[0]:.3f} {coord[1]:.3f}' for coord in normalized_polygon])\n",
    "            up.write(f'0 {normalized_coords}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âà∂‰ΩúÈ™åËØÅÈõÜ\n",
    "for row in training_anno.iloc[:10000].iterrows():\n",
    "    shutil.copy(os.path.join(data_path, row[1].Path), yolo_seg_dataset_valid_path)\n",
    "\n",
    "    img = cv2.imread(os.path.join(data_path, row[1].Path))\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    txt_filename = os.path.join(yolo_seg_dataset_valid_path + row[1].Path.split('/')[-1][:-4] + '.txt')\n",
    "    with open(txt_filename, 'w') as up:\n",
    "        for polygon in row[1].Polygons:\n",
    "            normalized_polygon = normalize_polygon(polygon, img_width, img_height)\n",
    "            normalized_coords = ' '.join([f'{coord[0]:.3f} {coord[1]:.3f}' for coord in normalized_polygon])\n",
    "            up.write(f'0 {normalized_coords}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(yolo_seg_dataset_path, \"data.yaml\"), 'w') as up:\n",
    "    data_root = os.path.abspath(yolo_seg_dataset_path)\n",
    "    up.write(f'''\n",
    "path: {data_root}\n",
    "train: train\n",
    "val: valid\n",
    "\n",
    "names:\n",
    "    0: alter\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model & Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://mirror.coggle.club/yolo/Arial.ttf -O /home/tipriest/.cache/torch/hub/checkpoints/Arial.ttf\n",
    "# !wget http://mirror.coggle.club/yolo/yolov8n-v8.2.0.pt -O /home/tipriest/.cache/torch/hub/checkpoints/yolov8n.pt\n",
    "# !wget http://mirror.coggle.club/yolo/yolov8n-seg-v8.2.0.pt -O /home/tipriest/.cache/torch/hub/checkpoints/yolov8n-seg.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tipriest/anaconda3/envs/AIdefense/lib/python3.10/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.12 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.0 üöÄ Python-3.10.14 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4080 SUPER, 15959MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=/home/tipriest/.cache/torch/hub/checkpoints/yolov8m-seg.pt, data=/home/tipriest/data/seg_risky/dataset/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train5\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   5159603  ultralytics.nn.modules.head.Segment          [1, 32, 192, [192, 384, 576]] \n",
      "YOLOv8m-seg summary: 331 layers, 27240227 parameters, 27240211 gradients, 110.4 GFLOPs\n",
      "\n",
      "Transferred 531/537 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tipriest/anaconda3/envs/AIdefense/lib/python3.10/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tipriest/anaconda3/envs/AIdefense/lib/python3.10/site-packages/ultralytics/utils/checks.py:640: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "/home/tipriest/anaconda3/envs/AIdefense/lib/python3.10/site-packages/ultralytics/engine/trainer.py:261: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/tipriest/data/seg_risky/dataset/train... 53785 images, 0 backgrounds, 18 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53785/53785 [00:21<00:00, 2509.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/00738a265eff3a4a47af81fc7035bfa5.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.221     1.0120001]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/00ec0e9dfb68e706a1bd059949073112.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.023]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/036f9c42ccb5342307995f88171f956f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/03a26fcbd2f13b33b63becea41766b01.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.002]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/044090b5e3ee683ecc47added8b9e2e2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.016]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/04c146f2ed1c8fec418a52d995171092.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/04ef9b36f47593acfb7d33524e94f542.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/0636d3d1f59b69361854917ee62b6bad.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/06be9b47da41283588a7d07d579c04c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.02]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/06cdfc3ec6e36ba5a7a37c54877ba5a7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.47  1.158]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/06d584f1c17fcc3b725e6c6519a2d17d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.4005 1.035 ]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/0720a0851f3e3755b73044540f0d965f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.008]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/0978c73b2c4c28ea1a02f31eb175fd44.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0079999]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/0abacd8e36a827623347f6df3703340e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.025]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/0bd4daf5a3f6b04a2b86a0dee04ae8ad.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.05]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/0e484b89d0aa399384c2e59692962a42.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.004]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/0ede2fd2a0b90fa5803633c051f1bb36.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.01]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/train/0f6f49ec46638fd24001027efdce11c1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0600001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/tipriest/data/seg_risky/dataset/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/tipriest/data/seg_risky/dataset/valid... 10000 images, 0 backgrounds, 2 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:04<00:00, 2315.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/valid/033c9b3f421abbee6213c381f5b16092.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.028]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /home/tipriest/data/seg_risky/dataset/valid/08daf3b15a7450f2a424ea46732a8ee4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.043]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/tipriest/data/seg_risky/dataset/valid.cache\n",
      "Plotting labels to runs/segment/train5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 512 train, 512 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train5\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      5.05G      1.508      1.678      1.853      1.286         16        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [07:11<00:00,  7.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:40<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.715      0.533      0.614      0.401      0.712       0.53      0.607      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      5.26G      1.392      1.397      1.523      1.204         15        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:55<00:00,  8.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.714      0.495      0.586       0.39       0.71      0.493      0.582      0.348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      5.26G      1.456      1.443      1.633       1.25         27        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:56<00:00,  8.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.718       0.52      0.598      0.392      0.716      0.516      0.592      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      5.38G      1.443      1.436      1.602      1.261         19        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:55<00:00,  8.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.823      0.617      0.712      0.495      0.823      0.616      0.709      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30       5.3G      1.335      1.359      1.413      1.206         14        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:57<00:00,  8.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.856      0.672       0.77      0.557      0.853      0.671      0.766      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      5.18G      1.262      1.303      1.287      1.169         22        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:57<00:00,  8.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.882      0.716      0.812      0.601      0.883       0.71      0.806       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      5.25G       1.22      1.261       1.21      1.149         18        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:56<00:00,  8.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.887      0.737      0.829      0.624      0.886      0.733      0.824      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      5.26G      1.185      1.233      1.151      1.131         17        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:56<00:00,  8.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.898      0.752      0.844      0.647      0.902      0.747      0.839      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      5.25G      1.148      1.209      1.097      1.113         28        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:57<00:00,  8.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.913      0.767      0.857      0.664      0.915      0.762      0.852      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30       5.2G      1.127      1.181       1.06      1.102         21        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:56<00:00,  8.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.919      0.781      0.869      0.679       0.92      0.777      0.865      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30       5.2G      1.111      1.168      1.028      1.096         19        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:56<00:00,  8.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.917      0.794      0.876       0.69      0.914      0.792      0.871      0.574\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      5.23G      1.085      1.151     0.9909      1.081         17        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:56<00:00,  8.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:38<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.925      0.801      0.882      0.698      0.926      0.797      0.877      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30      5.25G      1.066      1.138     0.9663      1.071         16        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:58<00:00,  8.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680       0.93       0.81      0.891      0.708      0.927      0.806      0.885      0.585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      5.16G      1.047       1.12     0.9374      1.063         16        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:58<00:00,  8.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.936       0.81      0.895      0.715      0.928      0.811      0.889       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      5.19G      1.032      1.102     0.9109      1.056         15        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:56<00:00,  8.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.938      0.818        0.9      0.721      0.935      0.813      0.893      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      5.19G      1.021      1.094     0.8908      1.051         22        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:56<00:00,  8.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.938      0.825      0.903      0.726      0.937      0.819      0.897      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      5.21G      1.004      1.078     0.8686      1.045         21        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:58<00:00,  8.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.936      0.832      0.906       0.73      0.932      0.827      0.899      0.603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      5.19G     0.9915      1.067     0.8481      1.039         13        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:57<00:00,  8.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.939      0.833      0.908      0.733      0.936      0.829      0.902      0.605\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      5.19G     0.9794      1.053     0.8312      1.034         13        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:58<00:00,  8.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.938      0.836       0.91      0.737       0.94      0.829      0.903      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30       5.2G     0.9589      1.035      0.801      1.024         22        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:57<00:00,  8.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:38<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.945      0.834      0.912      0.739      0.941      0.831      0.905      0.609\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30       5.2G      0.941      1.009     0.7506      1.025         10        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:57<00:00,  8.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.944      0.838      0.914      0.742      0.942      0.835      0.908       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      5.18G     0.9258     0.9938      0.729      1.018         10        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:58<00:00,  8.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:38<00:00,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.946       0.84      0.916      0.745      0.945      0.835       0.91      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      5.15G     0.9062     0.9664     0.6983      1.008          8        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:57<00:00,  8.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.945      0.844      0.917      0.748      0.944      0.839      0.912      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      5.21G     0.8918      0.958     0.6768      1.002         12        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:58<00:00,  8.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:38<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.946      0.847      0.919       0.75      0.943      0.843      0.913      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      5.22G     0.8747     0.9449     0.6532     0.9938         16        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:58<00:00,  8.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.947      0.849       0.92      0.753      0.944      0.845      0.915      0.618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      5.37G     0.8578     0.9305     0.6298      0.985         13        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:57<00:00,  8.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680       0.95      0.849      0.922      0.755      0.947      0.846      0.916       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      5.18G     0.8378     0.9057      0.606     0.9786          8        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:59<00:00,  8.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.952      0.851      0.923      0.757      0.949      0.847      0.917      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      5.17G     0.8227     0.9011     0.5861     0.9732          8        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:58<00:00,  8.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.951      0.853      0.924       0.76       0.95      0.848      0.919      0.623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30      5.19G      0.805     0.8765     0.5674     0.9645          7        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:58<00:00,  8.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680       0.95      0.857      0.926      0.762      0.947      0.853      0.921      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      5.14G     0.7894     0.8673     0.5458     0.9577         12        512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3361/3361 [06:59<00:00,  8.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:39<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.952      0.858      0.927      0.764      0.949      0.855      0.922      0.626\n",
      "\n",
      "30 epochs completed in 3.817 hours.\n",
      "Optimizer stripped from runs/segment/train5/weights/last.pt, 54.8MB\n",
      "Optimizer stripped from runs/segment/train5/weights/best.pt, 54.8MB\n",
      "\n",
      "Validating runs/segment/train5/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.0 üöÄ Python-3.10.14 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4080 SUPER, 15959MiB)\n",
      "YOLOv8m-seg summary (fused): 245 layers, 27222963 parameters, 0 gradients, 110.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:35<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       9998      14680      0.951      0.859      0.927      0.764      0.948      0.855      0.922      0.627\n",
      "Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model_base_path = \"/home/tipriest/.cache/torch/hub/checkpoints\"\n",
    "# yolov8n-seg„ÄÅyolov8s-seg„ÄÅyolov8m-seg„ÄÅyolov8l-segÂíåyolov8x-segÔºåÊ®°ÂûãÁöÑÂ§ßÂ∞è‰æùÊ¨°ÈÄíÂ¢û\n",
    "model = YOLO(os.path.join(model_base_path, \"yolov8m-seg.pt\"))\n",
    "results = model.train(data=os.path.join(yolo_seg_dataset_path, \"data.yaml\"), epochs=30, imgsz=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "model = YOLO(\"./runs/segment/train5/weights/best.pt\")\n",
    "\n",
    "test_imgs = glob.glob(os.path.join(data_path, \"test_set_A_rename/*/*\"))\n",
    "# test_imgs = glob.glob(os.path.join(data_path, \"data_set/train/0/*\"))\n",
    "# print(os.path.join(data_path, \"data_set/train/0/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100000/100000 [10:52<00:00, 153.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Polygon = []\n",
    "for path in tqdm(test_imgs[:]):\n",
    "    # print(path)\n",
    "    results = model(path, verbose=False)\n",
    "    result = results[0]\n",
    "    if result.masks is None:\n",
    "        Polygon.append([])\n",
    "    else:\n",
    "        image_polygons = []\n",
    "        for mask in result.masks.xy:\n",
    "            # Â∞ÜÊé©ËÜúÁöÑÂùêÊ†áËΩ¨Êç¢‰∏∫NumpyÊï∞ÁªÑ\n",
    "            mask_coords = np.array(mask)\n",
    "            # Ëé∑ÂèñÂ§ñÊé•Áü©ÂΩ¢(bounding box)\n",
    "            # print(mask_coords)\n",
    "            # print()\n",
    "            if 0 == mask_coords.size:\n",
    "                continue\n",
    "            x_min = round(float(np.min(mask_coords[:, 0])), 1)\n",
    "            x_max = round(float(np.max(mask_coords[:, 0])), 1)\n",
    "            y_min = round(float(np.min(mask_coords[:, 1])), 1)\n",
    "            y_max = round(float(np.max(mask_coords[:, 1])), 1)\n",
    "            bounding_box = [\n",
    "                [x_min, y_min],\n",
    "                [x_min, y_max],\n",
    "                [x_max, y_max],\n",
    "                [x_max, y_min]\n",
    "            ]\n",
    "            image_polygons.append(bounding_box)\n",
    "            # print(bounding_box)\n",
    "        Polygon.append(image_polygons)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "submit = pd.DataFrame({\n",
    "    'Path': [x.split('/')[-1] for x in test_imgs[:]],\n",
    "    'Polygon': Polygon\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.merge(submit, pd.DataFrame({'Path': [x.split('/')[-1] for x in test_imgs[:]]}), on='Path', how='right')\n",
    "submit = submit.fillna('[]')\n",
    "submit.to_csv('track2_submit.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algorithmPractice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
